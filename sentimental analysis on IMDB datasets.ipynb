{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5746323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      9912\n",
      "           1       0.87      0.88      0.87     10088\n",
      "\n",
      "    accuracy                           0.87     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.87      0.87      0.87     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\IMDB Dataset_1 (1).csv\")  # replace with your dataset filename\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna(subset=['review'])\n",
    "\n",
    "# Preprocessing\n",
    "max_features = 1000\n",
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Splitting dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model and the vectorizer\n",
    "import joblib\n",
    "joblib.dump(model, 'logistic_regression_sentiment_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9832af23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your movie review: A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Load the model and the vectorizer\n",
    "model = joblib.load('logistic_regression_sentiment_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Take input from the user\n",
    "user_input = input(\"Enter your movie review: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "user_input_vector = vectorizer.transform([user_input])\n",
    "\n",
    "# Predict sentiment\n",
    "predicted_sentiment = model.predict(user_input_vector)[0]\n",
    "\n",
    "# Map predicted sentiment label to human-readable form\n",
    "sentiment_label = label_encoder.inverse_transform([predicted_sentiment])[0]\n",
    "\n",
    "print(\"Predicted sentiment:\", sentiment_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711aacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
